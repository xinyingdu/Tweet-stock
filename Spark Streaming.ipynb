{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <div align=\"center\"> Part5 : Live streaming and processing the twitter data </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Twitter Stream API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Streaming APIs give developers low latency access to Twitterâ€™s global stream of Tweet data. A proper implementation of a streaming client will be pushed messages indicating Tweets and other events have occurred, without any of the overhead associated with polling a REST endpoint.\n",
    "\n",
    "Connecting to the streaming API requires keeping a persistent HTTP connection open. In many cases this involves thinking about your application differently than if you were interacting with the REST API."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tweepy API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tweepy is a Twitter API wrapper. You can access most of twitter REST and Stream API using Tweepy. In our project, we use Tweepy to access the twitter stream data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Python Server Program"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.config twitter API, assign access_token, access_secret, consumer_key, consumer_secret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tweepy\n",
    "from tweepy import OAuthHandler\n",
    "from tweepy import Stream\n",
    "from tweepy.streaming import StreamListener\n",
    "import socket\n",
    "import json\n",
    "\n",
    "\n",
    "#config twitter API credential here\n",
    "access_token = \"721369358241386496-9yGA7KdVhJFgYUKmT1QRKIhHaa9h5li\"\n",
    "access_secret = \"R63VZJtUCioxPSEbg41FzTxORke0uY5sX0UQyAeiadJ3x\"\n",
    "consumer_key = \"jOruEScM0dpmt5DKuh7fqL4IB\"\n",
    "consumer_secret = \"oLpHlVjRx9lV1cBncJJlPmH0NInA7rscR6ndULA7IiDwoXcJFN\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.define a tweetsListener, we need a python server program to read twitter stream from twitter and write the twitter stream into the socket. We create a socket binds to localhost port 5555, wait for the client to accept. Write twitter stream into the client as long as it accepts. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "     class TweetsListener(StreamListener):\n",
    "\n",
    "  def __init__(self, csocket):\n",
    "      self.client_socket = csocket\n",
    "\n",
    "  def on_data(self, data):\n",
    "      try:\n",
    "          msg = json.loads( data )\n",
    "          print (msg['created_at'],msg['user']['name'],msg['text'])\n",
    "          #print( msg['text'].encode('utf-8') )\n",
    "          self.client_socket.send( msg['text'].encode('utf-8') )\n",
    "          return True\n",
    "      except BaseException as e:\n",
    "          print(\"Error on_data: %s\" % str(e))\n",
    "      except:\n",
    "          self.sock.close()\n",
    "      return True\n",
    "      \n",
    "\n",
    "  def on_error(self, status):\n",
    "      print(status)\n",
    "      return True\n",
    "\n",
    "def sendData(c_socket):\n",
    "  auth = OAuthHandler(consumer_key, consumer_secret)\n",
    "  auth.set_access_token(access_token, access_secret)\n",
    "\n",
    "  twitter_stream = Stream(auth, TweetsListener(c_socket))\n",
    "  twitter_stream.filter(track=['@ebay','@amazon','@Target','@Walmart','@BestBuy'])\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "  s = socket.socket()         # Create a socket object\n",
    "  host = \"localhost\"      # Get local machine name\n",
    "  port = 5555                 # Reserve a port for your service.\n",
    "  s.bind((host, port))        # Bind to the port\n",
    "\n",
    "  print(\"Listening on port: %s\" % str(port))\n",
    "\n",
    "  s.listen(5)                 # Now wait for client connection.\n",
    "  c, addr = s.accept()        # Establish connection with client.\n",
    "\n",
    "  print( \"Received request from: \" + str( addr ) )\n",
    "\n",
    "  sendData( c )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## spark client program"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next steps is to start the spark program as a client program to get twitter stream from the socket."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.we need to import library and set environment path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Importing Library and setting environment path\n",
    "import os\n",
    "import sys\n",
    "#set the path \n",
    "os.environ['SPARK_HOME'] = \"C:/spark-2.0.2-bin-hadoop2.7\"\n",
    "sys.path.append(\"C:/park-2.0.2-bin-hadoop2.7/bin\")\n",
    "sys.path.append(\"C:/spark-2.0.2-bin-hadoop2.7/python\")\n",
    "sys.path.append(\"C:/spark-2.0.2-bin-hadoop2.7/python/pyspark\")\n",
    "sys.path.append(\"C:/spark-2.0.2-bin-hadoop2.7/python/pyspark/lib\")\n",
    "sys.path.append(\"C:/spark-2.0.2-bin-hadoop2.7/python/pyspark/lib/pyspark.zip\")\n",
    "sys.path.append(\"C:/spark-2.0.2-bin-hadoop2.7/python/pyspark/lib/py4j-0.10.3-src.zip\")\n",
    "sys.path.append(\"C:/Program Files/Java/jre1.8.0_77/bin\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.we should import all the module we need to our python spark program"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Streaming Program\n",
    "from pyspark import SparkContext\n",
    "from pyspark.streaming import StreamingContext\n",
    "from pyspark.sql import SQLContext\n",
    "from pyspark.sql.functions import desc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.get the sparkContext."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sc = SparkContext()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.set the streaming context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ssc = StreamingContext(sc, 10 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5.get the sqlContext."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sqlContext = SQLContext(sc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6.set streaming context checkpointing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ssc.checkpoint( \"file:///checkpoint\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7.create a Dstream from the socket we create from the server python program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "socket_stream = ssc.socketTextStream(\"localhost\", 5555)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8.perform window operation to the dstream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lines = socket_stream.window( 20 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9.give names to the fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import namedtuple\n",
    "fields = (\"tag\", \"count\" )\n",
    "Tweet = namedtuple( 'Tweet', fields )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10.perform MapReduce transformation to lines, register a temp table tweets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "(lines.flatMap( lambda text: text.split( \" \" ) )\n",
    "  .filter( lambda word: word.lower().startswith(\"@\") )\n",
    "  .map( lambda word: ( word.lower(), 1 ) )\n",
    "  .reduceByKey( lambda a, b: a + b )\n",
    "  .map( lambda rec: Tweet( rec[0], rec[1] ) ).foreachRDD(lambda rdd: rdd.toDF()\n",
    "  .sort(desc(\"count\")).limit(10).registerTempTable(\"tweets\"))\n",
    "   )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "11.start the stream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ssc.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "12.do sql qeury to the tweets table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "top_10_tweets = sqlContext.sql( 'select * from tweets limit 10' )\n",
    "top_10_tweets.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "13.import the pyplot "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sn\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "14.plot tag with count."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "from IPython import display\n",
    "\n",
    "\n",
    "count = 0\n",
    "while count < 10:\n",
    "  time.sleep( 20 )\n",
    "  top_10_tweets = sqlContext.sql( 'Select tag, count from tweets' )\n",
    "  top_10_df = top_10_tweets.toPandas()\n",
    "  display.clear_output(wait=True)\n",
    "  sn.plt.figure( figsize = ( 10, 8 ) )\n",
    "  sn.barplot( x=\"count\", y=\"tag\", data=top_10_df)\n",
    "  sn.plt.show()\n",
    "  count = count + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "15.stop the streaming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ssc.stop(False)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
